{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4mZ8KYblg-g"
   },
   "source": [
    "#installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4tlwQ8si_FI",
    "outputId": "088d7b24-ae0e-4709-8405-729b6151bd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 860M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y024z5AnlTLz",
    "outputId": "764e9746-9704-4497-d6b9-93efab106b1c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install optuna==2.3.0\n",
    "# !pip install transformers==4.2.1\n",
    "# !pip install farasapy\n",
    "# !pip install pyarabic\n",
    "# !git clone https://github.com/aub-mind/arabert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "krBvefg6l6vv"
   },
   "outputs": [],
   "source": [
    "# !pip install openpyxl\n",
    "# !pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVay9KamnC3I"
   },
   "source": [
    "#Creating training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "hr84ozGinCFh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "all_datasets= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "8PhWP2JzrEci"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name,\n",
    "        train,\n",
    "        test,\n",
    "        label_list,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.label_list = label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joWPYWGMqLau"
   },
   "source": [
    "##HARD - Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6oL3qkXmOgJ",
    "outputId": "e3047e51-11c1-4a13-ac6e-acc1658d977d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13    1025\n",
      "12     998\n",
      "11     755\n",
      "10     646\n",
      "9      574\n",
      "8      482\n",
      "7      477\n",
      "3      440\n",
      "5      425\n",
      "6      414\n",
      "4      410\n",
      "1      304\n",
      "2      292\n",
      "Name: tags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_HARD = pd.read_excel('ml2.xlsx', engine='openpyxl', header=None)\n",
    "df_HARD = df_HARD.rename(columns={0: 'tags', 1: 'post'})\n",
    "print(df_HARD[\"tags\"].value_counts())\n",
    "# code rating as +ve if > 3, -ve if less, no 3s in dataset\n",
    "\n",
    "train_HARD, test_HARD = train_test_split(df_HARD, test_size=0.2, random_state=42)\n",
    "label_list_HARD = list(range(1, 14))\n",
    "\n",
    "data_Hard = Dataset(\"ml2\", train_HARD, test_HARD, label_list_HARD)\n",
    "all_datasets.append(data_Hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFYs8DEEvHoX",
    "outputId": "8ac932c0-16e0-4cc0-f7b6-0ad70ba9c197"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml2\n"
     ]
    }
   ],
   "source": [
    "for x in all_datasets:\n",
    "  print(x.name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcwdslw7v0Q8"
   },
   "source": [
    "#Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HUn2RB6Bvrxj"
   },
   "outputs": [],
   "source": [
    "from arabert.preprocess import ArabertPreprocessor\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, BertTokenizer\n",
    "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
    "from transformers import Trainer , TrainingArguments\n",
    "from transformers.trainer_utils import EvaluationStrategy\n",
    "from transformers.data.processors.utils import InputFeatures\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import resample\n",
    "import logging\n",
    "import torch\n",
    "import optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KfNKr05tv7cA"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.WARNING)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R4SGYoB2EDJD",
    "outputId": "6e82ed5a-0f54-45f2-f866-bd54c1bee75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml2\n"
     ]
    }
   ],
   "source": [
    "for x in all_datasets:\n",
    "  print(x.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "62Lma6tT5zJi"
   },
   "source": [
    "You can choose which model, and dataset from here along with the max sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vzeVFoz1wDYf"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'ml2'\n",
    "model_name = 'aubmindlab/bert-base-arabertv2'\n",
    "task_name = 'classification'\n",
    "max_len = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ieCOj90aw8X",
    "outputId": "cbd57d7a-453a-49af-ccf2-efc3a6dcb4ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found\n"
     ]
    }
   ],
   "source": [
    "for d in all_datasets:\n",
    "  if d.name==dataset_name:\n",
    "    selected_dataset = d\n",
    "    print('Dataset found')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lt_lGy85zuca",
    "outputId": "004dafd1-0716-49dc-decf-03b54609a752"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-09-29 17:29:07,495 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
      "c:\\users\\maya\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\maya\\anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "arabert_prep = ArabertPreprocessor(\"bert-base-arabertv2\")\n",
    "\n",
    "selected_dataset.train['post'] = selected_dataset.train['post'].apply(lambda x: arabert_prep.preprocess(x))\n",
    "selected_dataset.test['post'] = selected_dataset.test['post'].apply(lambda x: arabert_prep.preprocess(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4YS7XI2bZTyz"
   },
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, text, target, model_name, max_len, label_map):\n",
    "      super(BERTDataset).__init__()\n",
    "      self.text = text\n",
    "      self.target = target\n",
    "      self.tokenizer_name = model_name\n",
    "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "      self.max_len = max_len\n",
    "      self.label_map = label_map\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.text)\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "      text = str(self.text[item])\n",
    "      text = \" \".join(text.split())\n",
    "\n",
    "\n",
    "        \n",
    "      input_ids = self.tokenizer.encode(\n",
    "          text,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          truncation='longest_first'\n",
    "      )     \n",
    "    \n",
    "      attention_mask = [1] * len(input_ids)\n",
    "\n",
    "      # Zero-pad up to the sequence length.\n",
    "      padding_length = self.max_len - len(input_ids)\n",
    "      input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "      attention_mask = attention_mask + ([0] * padding_length)    \n",
    "      \n",
    "      return InputFeatures(input_ids=input_ids, attention_mask=attention_mask, label=self.label_map[self.target[item]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "mciZOFz-amkV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12}\n"
     ]
    }
   ],
   "source": [
    "label_map = { v:index for index, v in enumerate(selected_dataset.label_list) }\n",
    "print(label_map)\n",
    "train_dataset = BERTDataset(selected_dataset.train['post'].to_list(),selected_dataset.train['tags'].to_list(),model_name,max_len,label_map)\n",
    "test_dataset = BERTDataset(selected_dataset.test['post'].to_list(),selected_dataset.test['tags'].to_list(),model_name,max_len,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "lt7l0IxjbmNu"
   },
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_name, return_dict=True, num_labels=len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UYU6G4vWc5nz"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p): #p should be of type EvalPrediction\n",
    "  preds = np.argmax(p.predictions, axis=1)\n",
    "  assert len(preds) == len(p.label_ids)\n",
    "  #print(classification_report(p.label_ids,preds))\n",
    "  #print(confusion_matrix(p.label_ids,preds))\n",
    "\n",
    "  macro_f1_per_label = f1_score(p.label_ids, preds,average='macro', labels=list(range(1, 14)))\n",
    "  macro_f1 = f1_score(p.label_ids,preds, average='macro')\n",
    "  macro_precision = precision_score(p.label_ids, preds,average='macro')\n",
    "  macro_recall = recall_score(p.label_ids, preds, average='macro')\n",
    "  acc = accuracy_score(p.label_ids, preds)\n",
    "  return {\n",
    "      'macro_f1' : macro_f1,\n",
    "      'macro_f1_per_label' : macro_f1_per_label,  \n",
    "      'macro_precision': macro_precision,\n",
    "      'macro_recall': macro_recall,\n",
    "      'accuracy': acc\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnqiZOT37ByE"
   },
   "source": [
    "# HyperParameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJif-78C6Kmn"
   },
   "source": [
    "you can change the batch size and gradient accumulation from here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "L3Z_kPB-dE_w"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"./train\")\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.adam_epsilon = 1e-8\n",
    "training_args.lr_scheduler_type = 'cosine'\n",
    "training_args.fp16 = True\n",
    "training_args.per_device_train_batch_size = 1\n",
    "training_args.per_device_eval_batch_size = 1\n",
    "training_args.gradient_accumulation_steps = 2\n",
    "training_args.num_train_epochs= 8\n",
    "training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
    "# training_args.logging_steps = 200\n",
    "training_args.save_steps = 100000\n",
    "# training_args.save_steps = \n",
    "#training_args.eval_steps = \n",
    "training_args.disable_tqdm = True\n",
    "# print(\"Logging Step:\", training_args.logging_steps)\n",
    "# print(\"Eval Step:\",training_args.eval_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeqRACPYheeb"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = (len(selected_dataset.train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "print(steps_per_epoch)\n",
    "print(total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8HOnY6odcwG"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=test_dataset, \n",
    "    model_init=model_init,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CHULcuX6a48"
   },
   "source": [
    "here you can define your search space.\n",
    "\n",
    "the `my_hp_space` function defines the hyper parameter super set, of which you can choose a subset (or even the whole set) for the grid search\n",
    "\n",
    "\n",
    "Note: You can include the opch count as a hyperparameter, but this will drasticly increase the search space, I prefer setting a fixed epcoh size, then I manually search for the highest score between the epochs since optuna can't do that as far as I know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXwkOzRCdsIZ",
    "outputId": "3d53ba88-0e12-422a-be98-65890efb75c9"
   },
   "outputs": [],
   "source": [
    "def my_hp_space(trial):\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 7e-5, step=1e-5),\n",
    "        \"seed\": trial.suggest_categorical(\"seed\", [0, 1, 42, 666, 123, 12345]),\n",
    "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\",0,total_steps*0.1,step=total_steps*0.1*0.5)\n",
    "    }\n",
    "\n",
    "search_space = {\n",
    "    \"learning_rate\":  list(np.arange(2e-5, 7e-5, 1e-5)),\n",
    "    \"seed\":  [0, 1, 42, 666, 123, 12345],\n",
    "    \"warmup_steps\": list(range(0, int((total_steps)*0.1)+1, int(total_steps*0.1*0.5)))\n",
    "}\n",
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwcBc70Sfem3"
   },
   "outputs": [],
   "source": [
    "def my_objective(metrics):\n",
    "    return metrics['eval_macro_f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc4gOvtE66Mj"
   },
   "source": [
    "choose a study name to save it on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSGLnBKv64sZ"
   },
   "outputs": [],
   "source": [
    "name = \"ml2-arabert-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7l821sW7fdaY"
   },
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(direction=\"maximize\",\n",
    "                                         hp_space=my_hp_space,\n",
    "                                         compute_objective=my_objective,\n",
    "                                         n_trials=None,\n",
    "                                         pruner=optuna.pruners.NopPruner(),\n",
    "                                         sampler=optuna.samplers.GridSampler(search_space),\n",
    "                                         study_name=name,\n",
    "                                         load_if_exists=False # you can change this to true, for continuing the search\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVwfM9ZJf12t"
   },
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTmvFEs41WkV"
   },
   "source": [
    "### Regular Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_oGjIC-7Vow"
   },
   "source": [
    "This paert allows you to do a regular training with no hyper parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u9xjs-X14uc0"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\"./train\")\n",
    "training_args.evaluate_during_training = True\n",
    "training_args.adam_epsilon = 1e-8\n",
    "training_args.learning_rate = 5e-5\n",
    "training_args.fp16 = True\n",
    "training_args.per_device_train_batch_size = 16\n",
    "training_args.per_device_eval_batch_size = 16\n",
    "training_args.gradient_accumulation_steps = 2\n",
    "training_args.num_train_epochs= 8\n",
    "\n",
    "\n",
    "steps_per_epoch = (len(selected_dataset.train)// (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps))\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "print(steps_per_epoch)\n",
    "print(total_steps)\n",
    "#Warmup_ratio\n",
    "warmup_ratio = 0.1\n",
    "training_args.warmup_steps = total_steps*warmup_ratio # or you can set the warmup steps directly \n",
    "\n",
    "training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
    "# training_args.logging_steps = 200\n",
    "training_args.save_steps = 100000 #don't want to save any model, there is probably a better way to do this :)\n",
    "training_args.seed = 42\n",
    "training_args.disable_tqdm = False\n",
    "training_args.lr_scheduler_type = 'cosine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ro5BW5ak4uc1"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model_init(),\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yx336O3J2SdQ"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Seyz8Yaj2ZCK"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"ml2\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5EZF6bJbtq5X",
    "MA5607R9jU3a",
    "AANFYzSruvH9"
   ],
   "name": "AraBERT-Trainer-Optuna-SA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
