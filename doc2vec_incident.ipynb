{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tags                                               post\n",
      "1    11  عند التاسعة من مساء يوم 29/9/2018 وفي محلة الط...\n",
      "2     4  اقدم المدعو وليد عدنان مرعي على شتم و اهانة ال...\n",
      "3    12  أقدم المدعو ناصر رضا على اصدار شك لصالح حسن اح...\n",
      "4     1  الساعة 7.30 من تاريخه وفي محلة فردان شارع كرام...\n"
     ]
    }
   ],
   "source": [
    "#readind and preparing data ( text , label )\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_excel('incident13type.xlsx', header=None) ## read le file\n",
    "df.columns=['tags','post']\n",
    "print(df[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.post, df.tags, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['الساعة', '14:45', 'من', 'تاريخه', 'اصطدمت', 'الدراجة', 'النارية', 'نوع', 'لين', 'هاي', 'لون', 'موف', 'صنع', '2017', 'رقم', '874626/م', 'بقيادة', 'المدعو', 'محمد', 'احمد', 'عواضة', 'والدته', 'حنان', 'تولد', '1990', 'لبناني', 'بفان', 'نوع', 'مازدا', 'صنع', '1996', 'لون', 'ابيض', 'رقم', '374181/م', 'بقيادة', 'علي', 'عباس', 'زعيتر', 'والدته', 'نور', 'تولد', '1997', 'لبناني', 'نتج', 'عن', 'الحادث', 'اصابة', 'الاول', 'بكسور', 'في', 'الوجه', 'نقل', 'الى', 'مستشفى', 'الجامعة', 'الاميريكية', 'للمعالجة', '،', 'نظم', 'محضر', 'رقم', '302/248'], tags=['Train_0']),\n",
       " TaggedDocument(words=['سلمتنا', 'دورية', 'من', 'فصيلتنا', 'المدعو', 'خالد', 'عيسى', '/', 'سوري', 'بجرم', 'دخول', 'البلاد', 'خلسة', 'وذلك', 'بعد', 'توقيفه', 'في', 'محلة', 'الروشة', 'الساعة', '18:00'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maya\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1192370.71it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2386448.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2388158.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1202696.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1200098.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2422291.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2385879.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1194507.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2385879.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2383036.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2382468.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1202262.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2387018.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2390442.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2393303.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2381333.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2347786.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2388729.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1200674.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1192512.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2381901.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1191802.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1201251.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1202696.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1191092.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2383604.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2379633.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 2383036.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1191660.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1192512.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 2384/2384 [00:00<00:00, 1200819.11it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Maya\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7625698324022346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.77      0.72        83\n",
      "           2       0.41      0.42      0.41        31\n",
      "           3       0.93      0.93      0.93       120\n",
      "           4       0.31      0.24      0.27        21\n",
      "           5       0.44      0.53      0.48        15\n",
      "           6       0.31      0.25      0.28        20\n",
      "           7       0.89      0.82      0.85       150\n",
      "           8       0.79      0.73      0.76        15\n",
      "           9       0.72      0.87      0.79        62\n",
      "          10       0.56      0.49      0.52        39\n",
      "          11       0.95      0.90      0.93        63\n",
      "          12       0.89      1.00      0.94        25\n",
      "          13       0.72      0.69      0.71        72\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       716\n",
      "   macro avg       0.66      0.67      0.66       716\n",
      "weighted avg       0.76      0.76      0.76       716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
